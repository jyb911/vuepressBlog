```c++
void H264Transcoding::h264ToMp4(const char *infile, const char *outfile){
    // 视频流所在的输入视频的AVStream数组索引
    int videoIdx = -1;
    // 封装格式上下文，保存视频文件封装格式相关信息
    AVFormatContext* pInputAVFormateContext = nullptr;
    // 输出封装格式
    AVOutputFormat* pAVOutputFormate = nullptr;
    // 打开视频文件，pInputAVFormateContext是一个AVFormatContext指针(调用avformat_alloc_context分配)，如果是空指针，则在avformat_open_input中被分配
    int ret = avformat_open_input(&pInputAVFormateContext, infile, nullptr, nullptr);
    if(ret < 0) return;
    qDebug() << "视频时长:" << pInputAVFormateContext->duration/1000000.0 << "s";
    qDebug() << "视频平均混合码率:" << pInputAVFormateContext->bit_rate/1000 << "Kbps";

    ret = avformat_find_stream_info(pInputAVFormateContext,nullptr);
    if(ret != 0){
        return;
    }
//    av_dump_format(pInputAVFormateContext,0,infile,0);

    // 输出封装格式上下文
    AVFormatContext* pOutputFormatContext = nullptr;
    ret = avformat_alloc_output_context2(&pOutputFormatContext,nullptr,"mp4",outfile);
    if(ret < 0){
        return;
    }

    /* 通过判断outfile的格式，转化成不同格式的数据
    pAVOutputFormate = av_guess_format(nullptr, outfile, nullptr);
    pOutputFormatContext->oformat = pAVOutputFormate;
    */

    // 输出封装格式文件的格式设置
    pAVOutputFormate = pOutputFormatContext->oformat;
    // nb_sreams: 输入视频的AVStream个数
    for(uint i = 0; i < pInputAVFormateContext->nb_streams; i++){
        AVStream* pInputAVStream = pInputAVFormateContext->streams[i];
        // 新建视频流
        AVStream* pOutputAVStream = avformat_new_stream(pOutputFormatContext,nullptr);
        // 编码器参数的设置
        ret = avcodec_parameters_copy(pOutputAVStream->codecpar,pInputAVStream->codecpar);
        if(ret < 0) return;
        pOutputAVStream->codecpar->codec_tag = 0;
    }

    for(uint i = 0; i < pInputAVFormateContext->nb_streams; i++){
        if(pInputAVFormateContext->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO){
            // 找到视频流的索引
            videoIdx = i;
            break;
        }
    }

//    av_dump_format(pOutputFormatContext,0,outfile,1);
    // 打开视频流
    ret = avio_open(&pOutputFormatContext->pb,outfile,AVIO_FLAG_WRITE);
    if(ret < 0) return;
    // 写入头部信息
    ret = avformat_write_header(pOutputFormatContext, nullptr);
    if(ret < 0) return;

    AVPacket pkt;
//    std::int64_t iistartTime = av_gettime();
    std::int64_t iiframeIndex = 0;

    while(true){
        AVStream* pInputStream = nullptr;
        AVStream* pOutputStream = nullptr;
        ret = av_read_frame(pInputAVFormateContext, &pkt);
        if(ret < 0) break;
        emit oneFrame(pkt.size);
        // 查看是否有做时间基的设置
        if(pkt.pts == AV_NOPTS_VALUE){ // 没有设置时间基
            // 时间基转换
            AVRational time_base1 = pInputAVFormateContext->streams[videoIdx]->time_base;
            std::int64_t iicalcDuration = (double)AV_TIME_BASE / av_q2d(pInputAVFormateContext->streams[videoIdx]->r_frame_rate);
            pkt.pts = (double)(iiframeIndex * iicalcDuration) / (double(av_q2d(time_base1) * AV_TIME_BASE));
            // 解码时间基(dts)
            pkt.dts = pkt.pts;  // 没有B帧
            // 目标两帧之间的长度
            pkt.duration = (double)iicalcDuration / (double)(av_q2d(time_base1) * AV_TIME_BASE);
        }
//        if(pkt.stream_index == videoIdx){
//            AVRational time_base = pInputAVFormateContext->streams[videoIdx]->time_base;
//            AVRational time_base_q = {1, AV_TIME_BASE};
//            std::int64_t pts_time = av_rescale_q(pkt.dts, time_base, time_base_q);
//            std::int64_t now_time = av_gettime() - iistartTime;
//        }

        pInputStream = pInputAVFormateContext->streams[pkt.stream_index];
        pOutputStream = pOutputFormatContext->streams[pkt.stream_index];
        // 显示时间基的转换
        pkt.pts = av_rescale_q_rnd(pkt.pts, pInputStream->time_base, pOutputStream->time_base,(AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
        // 解码时间基的转换
        pkt.dts = av_rescale_q_rnd(pkt.dts, pInputStream->time_base, pOutputStream->time_base,(AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
        // 数据时长的设置
        pkt.duration = (int)av_rescale_q(pkt.duration, pInputStream->time_base, pOutputStream->time_base);
        pkt.pos = -1;

        if(pkt.stream_index == videoIdx){ iiframeIndex++; }
        // 转码后的数据包，写入目标视频信息结构体中
        ret = av_interleaved_write_frame(pOutputFormatContext, &pkt);
        if(ret < 0) break;

        av_packet_unref(&pkt);
    }
    // 写入尾巴帧
    av_write_trailer(pOutputFormatContext);
    if(!(pOutputFormatContext->oformat->flags & AVFMT_NOFILE)){
        // 关闭各种流
        avio_close(pOutputFormatContext->pb);
    }
    avformat_free_context(pOutputFormatContext);

//    avio_close(pInputAVFormateContext->pb);
    avformat_close_input(&pInputAVFormateContext);


}
```

